{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadJar(jar:String) = interp.load.cp(os.Path(s\"${os.pwd}/libs/$jar\"))\n",
    "\n",
    "List(\"gcs-connector-hadoop2-latest.jar\", \"spark-bigquery-latest_2.12.jar\", \"spark-avro_2.12-3.0.1.jar\")\n",
    "    .foreach(loadJar)\n",
    "\n",
    "import $ivy.`org.apache.spark::spark-sql:3.0.1`\n",
    "import org.apache.spark.sql.{ Dataset, DataFrame, SparkSession }\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.types._\n",
    "import org.apache.spark.sql.expressions.{ Window }\n",
    "\n",
    "val spark = SparkSession.builder.master(\"local[*]\").getOrCreate\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "import spark.implicits._\n",
    "\n",
    "List(\"sparketl-core_2.12-1.4.0.jar\", \"format-preserving-encryption-1.0.0.jar\", \"ojdbc8-19.7.0.0.jar\")\n",
    "    .foreach(loadJar)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome! Run first line to create spark:SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.12",
   "language": "scala",
   "name": "scala212"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}